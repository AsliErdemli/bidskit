#!/usr/bin/env python3
"""
Convert flat DICOM file set into an NDAR-compliant fileset

Usage
----
dcm2ndar.py -i <DICOM Directory> -o <NDAR Directory>

Example
----
% dcm2ndar.py -i sub-001 -o sub-001.ndar

Authors
----
Mike Tyszka, Caltech Brain Imaging Center

Dates
----
2016-08-09 JMT Adapt from dcm2bids.py

MIT License

Copyright (c) 2016 Mike Tyszka

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""

__version__ = '0.1.0'

import os
import sys
import argparse
import subprocess
import shutil
import json


def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Convert DICOM files to NDAR-compliant fileset')
    parser.add_argument('-i', '--indir', required=True, help='Input directory containing flat DICOM images')
    parser.add_argument('-o', '--outdir', required=False, help='Output NDAR directory')
    parser.add_argument('-x', '--excludes', required=False, nargs='+', help='Protocol exclusion list [Localizer, HARDI, Clinical]')

    # Parse command line arguments
    args = parser.parse_args()

    dcm_dir = args.indir

    if args.outdir:
        ndar_dir = args.outdir
    else:
        ndar_dir = args.indir + '.ndar'

    if args.excludes:
        prot_excludes = args.excludes
    else:
        prot_excludes = ['Localizer', 'HARDI', 'Clinical']

    print('DICOM source directory : ' + dcm_dir)
    print('NDAR output directory  : ' + ndar_dir)
    print('Excluding protocols containing : ', end='')
    for s in prot_excludes:
        print(s, end=' ')
    print('')

    # Safe create output directory
    subprocess.call(['rm', '-rf', ndar_dir])
    subprocess.call(['mkdir', '-p', ndar_dir])

    # Run dcm2niix conversion from DICOM to Nifti with BIDS sidecars for metadata
    # This relies on the current CBIC branch of dcm2niix which extracts additional DICOM fields
    # required by NDAR
    subprocess.call(['dcm2niix', '-b', 'y', '-o', ndar_dir, dcm_dir])

    # Get list of files generated by dcm2niix in the NDAR directory
    dlist = os.listdir(ndar_dir)

    # Get list of unique subjects by name from file list
    sid_list = get_unique_subjects(dlist)

    # Loop over all subjects
    for sid in sid_list:

        print('Processing subject ' + sid)

        # Create subject directory
        sid_prefix = 'sub-' + sid
        sid_dir = os.path.join(ndar_dir, sid_prefix)

        print('  Creating subject directory')
        subprocess.call(['mkdir', '-p', sid_dir])

        # Create NDAR summary CSV for this subject
        ndar_fname = os.path.join(sid_dir, sid_prefix + '_NDAR.csv')
        ndar_fd = ndar_init_summary(ndar_fname)

        # Loop over all files for this SID
        for fname in os.listdir(ndar_dir):

            fname_full = os.path.join(ndar_dir, fname)

            if os.path.isfile(fname_full): # Restrict to files (exclude directories)

                # Parse filename
                print('  Parsing file name for SID and protocol')
                SID, prot, fstub, fext = ndar_parse_filename(fname)

                # Check for excluded protocol
                if ndar_include_prot(prot, prot_excludes):

                    if fstub.startswith(sid_prefix):

                        if fext == 'json':

                            print('  Reading JSON info')

                            # Read JSON sidecar for this file
                            json.fd = open(fname_full, 'r')
                            info = json.load(json.fd)

                            # Add SID to info dictionary
                            info['SID'] = SID

                            # Add row to NDAR summary CSV file
                            ndar_add_row(ndar_fd, info)

                            # Delete JSON file
                            print('  Deleting JSON file')
                            subprocess.call(['rm', '-rf', fname_full])

                        elif fext.startswith('nii'):

                            # Move image file into subject directory
                            print('  Moving image file to subject directory')
                            shutil.move(os.path.join(ndar_dir, fname), os.path.join(sid_dir, fname))

                else:
                    print('* Excluding file ' + fname)
                    subprocess.call(['rm', '-rf', fname_full])

        # Close NDAR summary file for this subject
        ndar_close_summary(ndar_fd)

    # Clean exit
    sys.exit(0)


def get_unique_subjects(dlist):
    """
    Construct list of unique SIDs in directory from filenames
    :param dlist:
    :return:
    """

    # Create an empty set for subject names
    SID_set = set()

    for fname in dlist:

        # Parse filename for SID, protocol string, file stub and extension
        SID, prot, fstub, fext = ndar_parse_filename(fname)
        SID_set.add(SID)

    # Convert set to list
    SID_list = list(SID_set)

    return SID_list


def ndar_parse_filename(fname):
    """
    Extract SID and protocol string from filename in the form sub-<SID>_<Protocol String>.*
    :param fname:
    :return: SID, prot, fstub, fext
    """

    # Init return values
    SID, prot, fstub, fext = 'None', 'None', 'None', 'None'

    # Split at first period to separate stub from extension(s)
    fstub, fext = fname.split('.',1)

    # Split stub at first underscore
    for chunk in fstub.split('_', 1):
        if chunk.startswith('sub-'):
            _, SID = chunk.split('-')
        else:
            prot = chunk

    return SID, prot, fstub, fext


def ndar_init_summary(fname):
    '''
    Open a summary CSV file and initialize with NDAR Image03 preamble
    :param fname:
    :return:
    '''

    ndar_fd = open(fname, 'w')
    ndar_fd.write('"image","03"\n')
    ndar_fd.write(
        '"subjectkey","src_subject_id","interview_date","interview_age","gender","comments_misc","image_file","image_thumbnail_file",')
    ndar_fd.write(
        '"image_description","experiment_id","scan_type","scan_object","image_file_format","data_file2","data_file2_type",')
    ndar_fd.write(
        '"image_modality","scanner_manufacturer_pd","scanner_type_pd","scanner_software_versions_pd","magnetic_field_strength",')
    ndar_fd.write(
        '"mri_repetition_time_pd","mri_echo_time_pd","flip_angle","acquisition_matrix","mri_field_of_view_pd","patient_position","photomet_interpret",')
    ndar_fd.write(
        '"receive_coil","transmit_coil","transformation_performed","transformation_type","image_history","image_num_dimensions",')
    ndar_fd.write(
        '"image_extent1","image_extent2","image_extent3","image_extent4","extent4_type","image_extent5","extent5_type",')
    ndar_fd.write(
        '"image_unit1","image_unit2","image_unit3","image_unit4","image_unit5","image_resolution1","image_resolution2",')
    ndar_fd.write(
        '"image_resolution3","image_resolution4","image_resolution5","image_slice_thickness","image_orientation",')
    ndar_fd.write(
        '"qc_outcome","qc_description","qc_fail_quest_reason","decay_correction","frame_end_times","frame_end_unit","frame_start_times",')
    ndar_fd.write('"frame_start_unit","pet_isotope","pet_tracer","time_diff_inject_to_image","time_diff_units",')
    ndar_fd.write('"pulse_seq","slice_acquisition","software_preproc","study","week","experiment_description","visit",')
    ndar_fd.write('"slice_timing","bvek_bval_files","bvecfile","bvalfile"')

    # Final newline
    ndar_fd.write('\n')

    return ndar_fd


def ndar_close_summary(fd):
    fd.close()
    return


def ndar_add_row(fd, info):
    """
    Write a single experiment row to the NDAR summary CSV file
    :param fd:
    :param info:
    :return:
    """

    # Field descriptions for NDAR Image03 MRI experiments
    # ElementName, DataType, Size, Required, ElementDescription, ValueRange, Notes, Aliases

    # subjectkey,GUID,,Required,The NDAR Global Unique Identifier (GUID) for research subject,NDAR*,,
    fd.write('" ",')

    # src_subject_id,String,20,Required,Subject ID how it's defined in lab/project,,,
    fd.write('"' + info['SID'] +'",')

    # interview_date,Date,,Required,Date on which the interview/genetic test/sampling/imaging was completed. MM/DD/YYYY,,Required field,ScanDate
    fd.write('" ",')

    # interview_age,Integer,,Required,Age in months at the time of the interview/test/sampling/imaging.,0 :: 1260,
    # "Age is rounded to chronological month. If the research participant is 15-days-old at time of interview,
    # the appropriate value would be 0 months. If the participant is 16-days-old, the value would be 1 month.",
    fd.write('" ",')

    # gender,String,20,Required,Sex of the subject,M;F,M = Male; F = Female,
    fd.write('" ",')

    # image_file,File,,Required,"Data file (image, behavioral, anatomical, etc)",,,file_source
    fd.write('" ",')

    # image_description,String,512,Required,"Image description, i.e. DTI, fMRI, Fast SPGR, phantom, EEG, dynamic PET",,,
    fd.write('" ",')

    # scan_type,String,50,Required,Type of Scan,
    # "MR diffusion; fMRI; MR structural (MPRAGE); MR structural (T1); MR structural (PD); MR structural (FSPGR);
    # MR structural (T2); PET; ASL; microscopy; MR structural (PD, T2); MR structural (B0 map); MR structural (B1 map);
    # single-shell DTI; multi-shell DTI; Field Map; X-Ray",,
    fd.write('" ",')

    # scan_object,String,50,Required,"The Object of the Scan (e.g. Live, Post-mortem, or Phantom",Live; Post-mortem; Phantom,,
    fd.write('"Live",')

    # image_file_format,String,50,Required,Image file format,
    # AFNI; ANALYZE; AVI; BIORAD; BMP; BRIK; BRUKER; CHESHIRE; COR; DICOM; DM3; FITS; GE GENESIS; GE SIGNA4X; GIF;
    # HEAD; ICO; ICS; INTERFILE; JPEG; LSM; MAGNETOM VISION; MEDIVISION; MGH; MICRO CAT; MINC; MIPAV XML; MRC; NIFTI;
    # NRRD; OSM; PCX; PIC; PICT; PNG; QT; RAW; SPM; STK; TIFF; TGA; TMG; XBM; XPM; PARREC; MINC HDF; LIFF; BFLOAT;
    # SIEMENS TEXT; ZVI; JP2; MATLAB; VISTA; ecat6; ecat7;,,
    fd.write('" ",')

    # image_modality,String,20,Required,Image modality, MRI;
    fd.write('"MRI",')

    # transformation_performed,String,4,Required,Performed transformation,Yes; No,,
    fd.write('"No",')

    # experiment_id,Integer,,Conditional,ID for the Experiment/settings/run,,,
    fd.write('" ",')

    # scanner_manufacturer_pd,String,30,Conditional,Scanner Manufacturer,,,
    fd.write('" ",')

    # scanner_type_pd,String,50,Conditional,Scanner Type,,,ScannerID
    fd.write('" ",')

    # magnetic_field_strength,String,50,Conditional,Magnetic field strength,,,
    fd.write('" ",')

    # mri_repetition_time_pd,Float,,Conditional,Repetition Time (seconds),,,
    fd.write('" ",')

    # mri_echo_time_pd,Float,,Conditional,Echo Time (seconds),,,
    fd.write('" ",')

    # flip_angle,String,30,Conditional,Flip angle,,,
    fd.write(',')

    # acquisition_matrix,String,30,Conditional,Acquisition matrix,,,
    fd.write('"",')

    # mri_field_of_view_pd,String,50,Conditional,Field of View,,,
    fd.write('"",')

    # patient_position,String,50,Conditional,Patient position,,,
    fd.write('"",')

    # photomet_interpret,String,50,Conditional,Photometric interpretation,,,
    fd.write('"",')

    # transformation_type,String,50,Conditional,Type of transformation,,,
    fd.write('"",')

    # image_extent2,Integer,,Conditional,Extent [2] Y dimension,1+,,
    fd.write('"",')

    # image_extent3,Integer,,Conditional,Extent [3] Z dimension,1+,,
    fd.write('"",')

    # image_extent4,Integer,,Conditional,Extent [4],,,
    fd.write('"",')

    # extent4_type,String,50,Conditional,Description of extent [4],,,
    fd.write('"",')

    # image_extent5,Integer,,Conditional,Extent [5],1+,,
    fd.write('"",')

    # extent5_type,String,50,Conditional,Description of extent [5],,,
    fd.write('"",')

    # image_unit2,String,20,Conditional,Units [2] Y dimension,
    # Inches; Centimeters; Angstroms; Nanometers; Micrometers; Millimeters; Meters; Kilometers; Miles;
    # Nanoseconds; Microseconds; Milliseconds; Seconds; Minutes; Hours; Hertz; frame number,,
    fd.write('"Millimeters",')

    # image_unit3,String,20,Conditional,Units [3] Z dimension,
    # Inches; Centimeters; Angstroms; Nanometers; Micrometers; Millimeters; Meters; Kilometers; Miles;
    # Nanoseconds; Microseconds; Milliseconds; Seconds; Minutes; Hours; Hertz; frame number,,
    fd.write('"Millimeters",')

    # image_unit4,String,50,Conditional,Units [4],
    # Inches; Centimeters; Angstroms; Nanometers; Micrometers; Millimeters; Meters; Kilometers; Miles;
    # Nanoseconds; Microseconds; Milliseconds; Seconds; Minutes; Hours; Hertz; Diffusion gradient;
    # frame number; number of Volumes (across time),,
    fd.write('"",')

    # image_unit5,String,20,Conditional,Units [5],
    # Inches; Centimeters; Angstroms; Nanometers; Micrometers; Millimeters; Meters; Kilometers; Miles;
    # Nanoseconds; Microseconds; Milliseconds; Seconds; Minutes; Hours; Hertz; Diffusion gradient; frame number,,
    fd.write('"",')

    # slice_timing,String,800,Conditional,
    # "The time at which each slice was acquired during the acquisition. Slice timing is not slice order - it describes
    # the time (sec) of each slice acquisition in relation to the beginning of volume acquisition. It is described
    # using a list of times (in JSON format) referring to the acquisition time for each slice. The list goes through
    # slices along the slice axis in the slice encoding dimension
    fd.write('"",')

    # bvek_bval_files,String,5,Conditional,
    # bvec and bval files provided as part of image_file for diffusion images only,Yes; No,,
    fd.write('"",')

    # bvecfile,File,,Conditional,
    # "Bvec file. The bvec files contain 3 rows with n space-delimited floating-point 5 numbers
    # (corresponding to the n volumes in the relevant Nifti file). The first row contains the x elements, the second
    # row contains the y elements and third row contains the z elements of a unit vector in the direction of the applied
    #  diffusion gradient, where the i-th elements in each row correspond together to the i-th volume with [0,0,0] for
    # non-diffusion-weighted volumes",,,
    fd.write('"",')

    # bvalfile,File,,Conditional,
    # "Bval file. The bval file contains the b-values (in s/mm2) corresponding to the volumes in the relevant Nifti file),
    # with 0 designating non-diffusion-weighted volumes, space-delimited
    fd.write('"",')

    # Final newline
    fd.write('\n')

    return


def strip_extensions(fname):
    fstub, fext = os.path.splitext(fname)
    if fext == '.gz':
        fstub, fext = os.path.splitext(fstub)
    return fstub


def ndar_include_prot(prot, prot_excludes):
    '''
    Returns False if protocol is in exclude list
    :param prot:
    :param prot_excludes:
    :return:
    '''

    status = True
    for pe in prot_excludes:
        if pe in prot:
            status = False

    return status

# This is the standard boilerplate that calls the main() function.
if __name__ == '__main__':
    main()
